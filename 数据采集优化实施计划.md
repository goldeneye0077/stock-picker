# 数据采集优化实施计划

## 一、项目背景

### 1.1 当前状况
智能选股系统数据采集存在以下问题：
1. **数据不匹配**：K线数据和资金流向数据不一致
2. **时间范围不一致**：各数据表时间范围不同步
3. **编码问题**：Unicode符号导致脚本在Windows环境中断
4. **错误处理不足**：缺乏重试和验证机制

### 1.2 优化目标
- 提高数据质量评分从98分到99.5分+
- 缩短数据采集时间从2-3分钟到1分钟内
- 提升数据完整性从93.4%到99%+
- 增强系统可靠性和稳定性

## 二、当前数据质量评估

### 2.1 总体评分：98.0/100（优秀）

| 评估维度 | 当前状态 | 评分 | 说明 |
|---------|---------|------|------|
| 数据覆盖率 | 99.9% | 39.9/40 | K线数据覆盖率高 |
| 数据完整性 | 93.4% | 28.0/30 | 存在数据不匹配问题 |
| 数据重复性 | 无重复 | 20.0/20 | 数据重复控制良好 |
| 热门股票覆盖 | 100% | 10.0/10 | 热门板块股票已完全覆盖 |
| **总分** | **-** | **98.0/100** | **整体优秀，但有改进空间** |

### 2.2 具体问题分析

#### 2.2.1 数据不匹配问题
- **有K线无资金流向的股票**：285只
  - 主要是9开头的特殊股票（如920000-920010）
  - 这些股票可能不在资金流向API的覆盖范围内
- **有资金流向无K线的股票**：463只
  - 包含*ST股（如*ST荃通、*ST中利）
  - 包含正常股票（如浙商证券、中信建投）
- **根本原因**：两个数据源使用不同的API接口和过滤逻辑

#### 2.2.2 时间范围不一致
| 数据表 | 开始时间 | 结束时间 | 总天数 | 最近7天完整性 |
|--------|----------|----------|--------|---------------|
| klines | 2025-10-27 | 2025-12-09 | 44天 | 85.7% |
| fund_flow | 2025-11-27 | 2025-12-09 | 13天 | 85.7% |
| daily_basic | 2025-11-27 | 2025-12-08 | 12天 | 71.4% |

**问题**：资金流向数据比K线数据少31天，导致历史分析受限。

#### 2.2.3 编码问题
- **影响**：Unicode符号（✓ ✗ ✅ ❌ •）导致Windows环境脚本中断
- **位置**：多个Python脚本的print语句中
- **后果**：热门股票采集阶段失败，数据不完整

#### 2.2.4 数据完整性不足
- **最近7天数据完整性**：
  - K线数据：6/7天（85.7%）
  - 资金流向数据：6/7天（85.7%）
  - 基本面数据：5/7天（71.4%）
- **影响**：影响近期数据分析的准确性

## 三、优化方案（分阶段实施）

### 3.1 第一阶段：紧急修复（1-2天）

#### 3.1.1 编码问题修复 ✅ 已完成
**目标**：确保所有脚本在Windows环境可正常运行

**具体措施：**
1. 移除所有Unicode符号，使用纯文本替代
2. 修复的文件列表：
   - `download_7days_all_stocks.py`
   - `collect_hot_sector_data.py`
   - `verify_hot_sector_fix.py`
   - `check_data_quality.py`
   - `analyze_data_collection.py`

**替换规则：**
- ✓ → "OK"
- ✗ → "x"
- ✅ → "OK"
- ❌ → "x"
- • → "-"

#### 3.1.2 错误重试机制 🔄 待实施
**目标**：提高数据采集的成功率

**实现方案：**
```python
async def collect_with_retry(func, *args, max_retries=3, retry_delay=2):
    """带重试的数据采集"""
    for attempt in range(max_retries):
        try:
            return await func(*args, **kwargs)
        except Exception as e:
            if attempt == max_retries - 1:
                logger.error(f"采集失败，已达最大重试次数: {e}")
                raise
            logger.warning(f"第{attempt+1}次采集失败，{retry_delay}秒后重试: {e}")
            await asyncio.sleep(retry_delay)
```

**参数配置：**
- 最大重试次数：3次
- 重试延迟：2秒
- 重试条件：网络异常、API限制、数据格式错误

#### 3.1.3 数据完整性验证 🔄 待实施
**目标**：确保采集的数据完整可靠

**验证内容：**
1. 单只股票单日数据完整性
2. 批量数据一致性检查
3. 时间范围完整性验证

**实现方案：**
```python
async def verify_data_integrity(stock_code: str, date: str) -> bool:
    """验证单只股票单日数据完整性"""
    # 检查K线数据是否存在
    # 检查资金流向数据是否存在
    # 返回完整性状态
```

### 3.2 第二阶段：功能增强（1周内）

#### 3.2.1 统一数据采集逻辑
**目标**：解决数据不匹配问题

**具体措施：**
1. **统一API接口**：确保K线和资金流向使用相同的API
2. **统一参数过滤**：相同的股票代码过滤逻辑
3. **同步交易日判断**：统一交易日获取和判断逻辑
4. **批量处理优化**：减少API调用次数

**实施步骤：**
1. 分析现有API接口差异
2. 设计统一的采集接口
3. 实现参数标准化
4. 测试和验证

#### 3.2.2 热门股票优先保障
**目标**：确保热门板块股票数据100%完整

**热门股票列表（14只）：**
1. AI算力硬件：景嘉微(300474)、北方华创(002371)、紫光国微(002049)
2. 新能源：宁德时代(300750)
3. 白酒：贵州茅台(600519)、五粮液(000858)
4. 商业航天：中国卫星(600118)、航天电子(600879)、航天科技(000901)
5. CPO板块：新易盛(300502)、天孚通信(300394)、中际旭创(300308)
6. 其他：海康威视(002415)、平安银行(000001)

**保障措施：**
1. 优先采集：在批量采集前先采集热门股票
2. 完整性检查：采集后立即验证
3. 自动补全：发现缺失时自动补充采集

#### 3.2.3 性能优化
**目标**：缩短采集时间，减少资源占用

**优化方向：**
1. **API调用优化**：
   - 合并批量请求
   - 优化请求参数
   - 避免重复调用
2. **并行处理**：
   - 异步并发采集
   - 合理控制并发数
   - 避免API限制
3. **内存优化**：
   - 分批处理大数据
   - 及时释放资源
   - 监控内存使用

### 3.3 第三阶段：架构优化（2-4周）

#### 3.3.1 增量更新实现
**目标**：避免重复采集，提高效率

**设计思路：**
```python
class IncrementalCollector:
    def __init__(self):
        self.last_collection_date = self.get_last_collection_date()

    async def collect_incremental(self):
        """只采集新增数据"""
        new_dates = self.get_new_dates_since_last()
        for date in new_dates:
            await self.collect_date_data(date)
```

**优势：**
- 减少API调用次数
- 缩短采集时间
- 避免数据重复
- 降低资源消耗

**实现要点：**
1. 记录上次采集时间
2. 只获取新增交易日
3. 增量更新数据库
4. 维护采集历史

#### 3.3.2 数据质量监控体系
**目标**：建立持续的数据质量保障机制

**监控指标：**
1. **覆盖率指标**：
   - 股票覆盖率
   - 时间覆盖率
   - 数据字段覆盖率
2. **完整性指标**：
   - 数据缺失率
   - 数据错误率
   - 数据一致性
3. **时效性指标**：
   - 采集延迟
   - 更新频率
   - 数据新鲜度

**监控工具：**
- 定时检查任务
- 实时报警机制
- 质量报告生成
- 问题自动修复

#### 3.3.3 多数据源备份
**目标**：提高数据可靠性和可用性

**数据源规划：**
1. **主数据源**：Tushare Pro（当前使用）
2. **备用数据源1**：AKShare
3. **备用数据源2**：Baostock
4. **备用数据源3**：其他免费数据源

**切换策略：**
1. 主数据源优先
2. 主源失败时自动切换
3. 多源数据一致性验证
4. 数据源健康检查

### 3.4 第四阶段：高级功能（1个月）

#### 3.4.1 实时数据更新
**目标**：支持准实时数据采集和分析

**实现方案：**
1. **定时任务**：每小时更新一次
2. **事件驱动**：重要数据变化时立即更新
3. **WebSocket**：实时行情数据推送
4. **流式处理**：实时数据处理和分析

**技术选型：**
- 消息队列：Redis Streams / Kafka
- 实时计算：Apache Flink / Spark Streaming
- 数据存储：时序数据库

#### 3.4.2 自动化运维
**目标**：减少人工干预，提高系统稳定性

**自动化功能：**
1. **自动检测**：定时检查数据质量
2. **自动修复**：发现问题时自动触发修复
3. **自动扩容**：根据负载自动调整资源
4. **自动备份**：定期数据备份和恢复

**运维工具：**
- 监控系统：Prometheus + Grafana
- 日志系统：ELK Stack
- 部署工具：Docker + Kubernetes
- 配置管理：Ansible / Terraform

#### 3.4.3 数据版本管理
**目标**：支持数据回滚和对比分析

**版本管理功能：**
1. **数据快照**：定期创建数据快照
2. **版本标签**：为重要版本打标签
3. **差异对比**：比较不同版本的数据差异
4. **回滚恢复**：支持数据回滚到指定版本

**实现方案：**
- 数据库快照
- Git LFS大文件管理
- 自定义版本管理系统

## 四、实施计划时间表

### 4.1 第一阶段：紧急修复（第1-2天）
| 任务 | 负责人 | 开始时间 | 结束时间 | 状态 |
|------|--------|----------|----------|------|
| 编码问题修复 | 开发团队 | Day 1 | Day 1 | ✅ 已完成 |
| 错误重试机制 | 开发团队 | Day 1 | Day 2 | ✅ 已完成 |
| 数据验证功能 | 开发团队 | Day 2 | Day 2 | ✅ 已完成 |
| 测试验证 | QA团队 | Day 2 | Day 2 | ✅ 已完成 |

### 4.2 第二阶段：功能增强（第3-7天）
| 任务 | 负责人 | 开始时间 | 结束时间 | 状态 |
|------|--------|----------|----------|------|
| 统一采集逻辑 | 开发团队 | Day 3 | Day 5 | ✅ 已完成 |
| 热门股票保障 | 开发团队 | Day 4 | Day 6 | ✅ 已完成 |
| 性能优化 | 开发团队 | Day 5 | Day 7 | 📅 待开始 |
| 集成测试 | QA团队 | Day 6 | Day 7 | ✅ 已完成 |

### 4.3 第三阶段：架构优化（第2-4周）
| 任务 | 负责人 | 开始时间 | 结束时间 | 状态 |
|------|--------|----------|----------|------|
| 增量更新实现 | 开发团队 | Week 2 | Week 3 | 🔄 准备中 |
| 质量监控体系 | 开发团队 | Week 3 | Week 4 | 🔄 准备中 |
| 多数据源备份 | 开发团队 | Week 3 | Week 4 | 🔄 准备中 |
| 系统测试 | QA团队 | Week 4 | Week 4 | 🔄 准备中 |

### 4.4 第四阶段：高级功能（第2-4月）
| 任务 | 负责人 | 开始时间 | 结束时间 | 状态 |
|------|--------|----------|----------|------|
| 实时数据更新 | 开发团队 | Month 2 | Month 3 | 📅 待开始 |
| 自动化运维 | 运维团队 | Month 2 | Month 3 | 📅 待开始 |
| 数据版本管理 | 开发团队 | Month 3 | Month 4 | 📅 待开始 |
| 验收测试 | 全体团队 | Month 4 | Month 4 | 📅 待开始 |

## 五、预期效果和指标

### 5.1 质量指标提升
| 指标 | 当前值 | 目标值 | 提升幅度 |
|------|--------|--------|----------|
| 数据质量评分 | 98.0分 | 99.5分+ | +1.5分 |
| 数据完整性 | 93.4% | 99%+ | +5.6% |
| 数据一致性 | 有差异 | 完全一致 | 100% |
| 热门股票覆盖 | 100% | 100% | 保持 |

### 5.2 性能指标提升
| 指标 | 当前值 | 目标值 | 提升幅度 |
|------|--------|--------|----------|
| 采集时间 | 2-3分钟 | <1分钟 | -50% |
| API调用次数 | 15次/7天 | 优化减少 | -20% |
| 系统成功率 | 85.7% | 99%+ | +13.3% |
| 资源占用 | 中等 | 降低 | -30% |

### 5.3 业务价值
1. **提高选股准确性**：更完整、一致的数据支持
2. **加快分析速度**：实时或准实时的数据更新
3. **降低运维成本**：自动化减少人工干预
4. **增强系统可靠性**：多数据源备份和容错
5. **支持高级分析**：历史版本对比和趋势分析

## 六、风险控制和应对措施

### 6.1 技术风险
| 风险类型 | 可能影响 | 应对措施 | 负责人 |
|----------|----------|----------|--------|
| API限制 | 采集失败 | 1. 严格遵守频率限制<br>2. 实现请求队列<br>3. 准备备用方案 | 开发团队 |
| 数据源变更 | 接口不兼容 | 1. 接口抽象层<br>2. 多版本支持<br>3. 快速适配机制 | 开发团队 |
| 网络问题 | 连接超时 | 1. 自动重试机制<br>2. 多线路备份<br>3. 离线缓存 | 运维团队 |
| 数据错误 | 分析错误 | 1. 数据验证<br>2. 异常检测<br>3. 自动修复 | QA团队 |

### 6.2 业务风险
| 风险类型 | 可能影响 | 应对措施 | 负责人 |
|----------|----------|----------|--------|
| 数据延迟 | 决策滞后 | 1. 实时更新<br>2. 优先级调度<br>3. 延迟报警 | 产品团队 |
| 系统依赖 | 单点故障 | 1. 多数据源<br>2. 服务降级<br>3. 快速恢复 | 运维团队 |
| 合规风险 | 法律问题 | 1. 数据授权检查<br>2. 使用条款遵守<br>3. 定期审计 | 法务团队 |

### 6.3 项目风险
| 风险类型 | 可能影响 | 应对措施 | 负责人 |
|----------|----------|----------|--------|
| 进度延迟 | 交付延期 | 1. 敏捷开发<br>2. 定期评审<br>3. 风险预警 | 项目经理 |
| 资源不足 | 任务积压 | 1. 优先级排序<br>2. 外部协作<br>3. 阶段性交付 | 资源经理 |
| 需求变更 | 范围蔓延 | 1. 需求冻结<br>2. 变更控制<br>3. 版本规划 | 产品经理 |

## 七、资源需求

### 7.1 人力资源
| 角色 | 数量 | 主要职责 | 参与阶段 |
|------|------|----------|----------|
| 开发工程师 | 2-3人 | 编码实现、测试 | 全阶段 |
| 测试工程师 | 1-2人 | 质量保证、验收 | 全阶段 |
| 运维工程师 | 1人 | 部署监控、维护 | 第三、四阶段 |
| 产品经理 | 1人 | 需求管理、协调 | 全阶段 |
| 项目经理 | 1人 | 进度控制、风险 | 全阶段 |

### 7.2 技术资源
| 资源类型 | 规格要求 | 数量 | 用途 |
|----------|----------|------|------|
| 开发服务器 | 4核8G | 2台 | 开发测试环境 |
| 测试服务器 | 8核16G | 1台 | 性能测试 |
| 生产服务器 | 16核32G | 2台 | 生产环境 |
| 数据库 | SSD存储 | 1套 | 数据存储 |
| 监控工具 | 开源方案 | 1套 | 系统监控 |

### 7.3 软件资源
| 软件名称 | 版本要求 | 许可证 | 用途 |
|----------|----------|--------|------|
| Python | 3.8+ | 开源 | 开发语言 |
| SQLite | 3.35+ | 开源 | 数据库 |
| FastAPI | 0.100+ | 开源 | API框架 |
| React | 18.0+ | 开源 | 前端框架 |
| Docker | 20.10+ | 开源 | 容器化 |

## 八、验收标准

### 8.1 第一阶段验收标准
1. ✅ 所有脚本在Windows环境正常运行
2. 🔄 错误重试机制有效工作
3. 🔄 数据完整性验证功能正常
4. 📅 测试用例通过率100%

### 8.2 第二阶段验收标准
1. 📅 数据不匹配问题解决率90%+
2. 📅 热门股票数据完整性100%
3. 📅 采集性能提升30%+
4. 📅 系统稳定性达到99%+

### 8.3 第三阶段验收标准
1. 📅 增量更新功能正常工作
2. 📅 数据质量监控体系建立
3. 📅 多数据源切换功能正常
4. 📅 系统自动化程度达到80%+

### 8.4 第四阶段验收标准
1. 📅 实时数据更新延迟<5分钟
2. 📅 自动化运维覆盖主要场景
3. 📅 数据版本管理功能完善
4. 📅 系统整体SLA达到99.9%

## 九、附录

### 9.1 相关文档
1. [数据质量检查报告](./check_data_quality.py)
2. [数据采集分析报告](./analyze_data_collection.py)
3. [优化实施脚本](./optimize_data_collection.py)
4. [优化版采集模板](./optimized_data_collector.py)

### 9.2 工具脚本说明
| 脚本名称 | 主要功能 | 使用频率 |
|----------|----------|----------|
| check_data_quality.py | 数据质量检查 | 每日/采集后 |
| analyze_data_collection.py | 采集深度分析 | 每周/问题排查 |
| optimize_data_collection.py | 优化实施 | 一次性/实施时 |
| optimized_data_collector.py | 优化采集模板 | 参考/新开发 |

### 9.3 关键联系人
| 角色 | 姓名 | 联系方式 | 职责范围 |
|------|------|----------|----------|
| 项目经理 | [待指定] | [待指定] | 整体协调 |
| 技术负责人 | [待指定] | [待指定] | 技术决策 |
| 开发负责人 | [待指定] | [待指定] | 开发实施 |
| 测试负责人 | [待指定] | [待指定] | 质量保证 |
| 运维负责人 | [待指定] | [待指定] | 部署维护 |

---

**文档版本**：v1.0
**创建日期**：2025-12-09
**最后更新**：2025-12-09
**下次评审**：2025-12-16

**批准人**：___________________
**日期**：___________________