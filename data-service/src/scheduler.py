"""
å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨æ¨¡å—
è‡ªåŠ¨åœ¨äº¤æ˜“æ—¥æ”¶ç›˜åŽé‡‡é›†è‚¡ç¥¨æ•°æ®
"""
import os
import sys
from datetime import datetime
from zoneinfo import ZoneInfo
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from loguru import logger
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°sys.path,ä»¥ä¾¿å¯¼å…¥æ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

env_path = Path(__file__).parent.parent / ".env"
load_dotenv(dotenv_path=env_path)

scheduler_tz = ZoneInfo(os.getenv("SCHEDULER_TZ", "Asia/Shanghai"))
scheduler = BackgroundScheduler(timezone=scheduler_tz)
_is_running = False


def is_trading_day() -> bool:
    today = datetime.now(scheduler_tz)
    is_weekday = today.weekday() < 5
    return is_weekday


async def collect_daily_data_task():
    try:
        if not is_trading_day():
            logger.info("ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥,è·³è¿‡æ•°æ®é‡‡é›†")
            return

        logger.info("â° å®šæ—¶ä»»åŠ¡è§¦å‘: å¼€å§‹é‡‡é›†æ¯æ—¥è‚¡ç¥¨æ•°æ®")

        try:
            from .routes.data_collection import batch_collect_7days_data
        except ImportError:
            from routes.data_collection import batch_collect_7days_data

        result = await batch_collect_7days_data()

        if result.get("success"):
            logger.info(f"âœ… å®šæ—¶æ•°æ®é‡‡é›†æˆåŠŸ: {result.get('message')}")
        else:
            logger.error(f"âŒ å®šæ—¶æ•°æ®é‡‡é›†å¤±è´¥: {result.get('message')}")

    except Exception as e:
        logger.error(f"âŒ å®šæ—¶ä»»åŠ¡æ‰§è¡Œé”™è¯¯: {e}")


async def collect_realtime_quotes_task():
    try:
        if not is_trading_day():
            logger.info("ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥,è·³è¿‡å®žæ—¶è¡Œæƒ…é‡‡é›†")
            return

        try:
            from .routes.quotes import update_realtime_quotes_task
        except ImportError:
            from routes.quotes import update_realtime_quotes_task
        try:
            from .data_sources.akshare_client import AKShareClient
        except ImportError:
            from data_sources.akshare_client import AKShareClient

        akshare_client = AKShareClient()
        await update_realtime_quotes_task(akshare_client)

        logger.info("é›†åˆç«žä»·å®žæ—¶è¡Œæƒ…é‡‡é›†ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
    except Exception as e:
        logger.error(f"å®žæ—¶è¡Œæƒ…é‡‡é›†ä»»åŠ¡æ‰§è¡Œé”™è¯¯: {e}")

async def collect_auction_data_task():
    try:
        if not is_trading_day():
            logger.info("ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥,è·³è¿‡é›†åˆç«žä»·é‡‡é›†")
            return
        try:
            from .routes.quotes import update_auction_from_tushare_task
        except ImportError:
            from routes.quotes import update_auction_from_tushare_task
        try:
            from .data_sources.tushare_client import TushareClient
        except ImportError:
            from data_sources.tushare_client import TushareClient
        tushare_client = TushareClient()
        await update_auction_from_tushare_task(tushare_client)
        logger.info("é›†åˆç«žä»·æ•°æ®é‡‡é›†ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
    except Exception as e:
        logger.error(f"é›†åˆç«žä»·é‡‡é›†ä»»åŠ¡æ‰§è¡Œé”™è¯¯: {e}")


def schedule_sync_wrapper():
    import asyncio
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(collect_daily_data_task())
        finally:
            loop.close()
    except Exception as e:
        logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
        import traceback
        logger.error(traceback.format_exc())


def realtime_schedule_sync_wrapper():
    import asyncio
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(collect_realtime_quotes_task())
        finally:
            loop.close()
    except Exception as e:
        logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
        import traceback
        logger.error(traceback.format_exc())

def auction_schedule_sync_wrapper():
    import asyncio
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(collect_auction_data_task())
        finally:
            loop.close()
    except Exception as e:
        logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
        import traceback
        logger.error(traceback.format_exc())


def start_scheduler():
    """
    å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
    """
    global _is_running

    if _is_running:
        logger.warning("è°ƒåº¦å™¨å·²ç»åœ¨è¿è¡Œä¸­")
        return

    try:
        scheduler.add_job(
            func=schedule_sync_wrapper,
            trigger=CronTrigger(
                hour=15,
                minute=30,
                day_of_week='mon-fri',
                timezone=scheduler_tz
            ),
            id='daily_data_collection',
            name='æ¯æ—¥è‚¡ç¥¨æ•°æ®é‡‡é›†',
            replace_existing=True,
            misfire_grace_time=3600
        )

        scheduler.add_job(
            func=realtime_schedule_sync_wrapper,
            trigger=CronTrigger(
                hour=9,
                minute='15-25',
                second='*/5',
                day_of_week='mon-fri',
                timezone=scheduler_tz
            ),
            id='auction_realtime_quotes',
            name='é›†åˆç«žä»·å®žæ—¶è¡Œæƒ…é‡‡é›†',
            replace_existing=True,
            misfire_grace_time=10
        )
        scheduler.add_job(
            func=auction_schedule_sync_wrapper,
            trigger=CronTrigger(
                hour=9,
                minute='26-29',
                second=0,
                day_of_week='mon-fri',
                timezone=scheduler_tz
            ),
            id='auction_stk_auction',
            name='é›†åˆç«žä»·æˆäº¤é‡‡é›†(Tushare)',
            replace_existing=True,
            misfire_grace_time=10
        )


        scheduler.start()
        _is_running = True

        logger.info("ðŸš€ å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")
        logger.info("ðŸ“… é‡‡é›†æ—¶é—´: æ¯å¤©15:30 (å‘¨ä¸€è‡³å‘¨äº”)")

        # æ˜¾ç¤ºä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
        next_run = scheduler.get_job('daily_data_collection').next_run_time
        if next_run:
            logger.info(f"â° ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´: {next_run.strftime('%Y-%m-%d %H:%M:%S')}")

    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨è°ƒåº¦å™¨å¤±è´¥: {e}")
        _is_running = False


def stop_scheduler():
    """
    åœæ­¢å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
    """
    global _is_running

    if not _is_running:
        return

    try:
        scheduler.shutdown(wait=False)
        _is_running = False
        logger.info("ðŸ›‘ å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²åœæ­¢")
    except Exception as e:
        logger.error(f"âŒ åœæ­¢è°ƒåº¦å™¨å¤±è´¥: {e}")


def get_scheduler_status():
    """
    èŽ·å–è°ƒåº¦å™¨çŠ¶æ€
    """
    if not _is_running:
        return {
            "running": False,
            "next_run_time": None,
            "jobs": []
        }

    try:
        jobs = []
        for job in scheduler.get_jobs():
            jobs.append({
                "id": job.id,
                "name": job.name,
                "next_run_time": job.next_run_time.isoformat() if job.next_run_time else None
            })

        return {
            "running": True,
            "jobs": jobs
        }
    except Exception as e:
        logger.error(f"èŽ·å–è°ƒåº¦å™¨çŠ¶æ€å¤±è´¥: {e}")
        return {
            "running": False,
            "error": str(e)
        }
